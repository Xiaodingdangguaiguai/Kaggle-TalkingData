{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "Models are ensembled using weight blending. This involves 3 Field-Aware Factorization Machine models and 3 LightGBM models. Weights are optimized using the <a href='https://github.com/pklauke/Ensemble'>Ensemble</a> package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation and test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18790469, 3)\n",
      "Mean:  [0.07576617 0.08030955 0.0792169 ]\n"
     ]
    }
   ],
   "source": [
    "files = ['instance-1/home/klauke_peter/predictions_test_new.csv', 'predictions_test_2.csv', 'predictions_test_3.csv']\n",
    "\n",
    "preds_test_lgb = np.concatenate([pd.read_csv(file).values[:, 1:] for file in files], axis=1)\n",
    "print(preds_test_lgb.shape)\n",
    "print('Mean: ', np.mean(preds_test_lgb, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2327952, 3)\n",
      "Mean:  [0.06339939 0.0675721  0.06784469]\n"
     ]
    }
   ],
   "source": [
    "files = ['instance-1/home/klauke_peter/predictions_valid_new.csv', 'predictions_valid_2.csv', 'predictions_valid_3.csv']\n",
    "\n",
    "preds_valid_lgb = np.concatenate([pd.read_csv(file).values[:, 1:] for file in files], axis=1)\n",
    "print(preds_valid_lgb.shape)\n",
    "print('Mean: ', np.mean(preds_valid_lgb, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18790469, 3)\n",
      "Mean:  [       nan 0.00337221        nan]\n"
     ]
    }
   ],
   "source": [
    "files = ['LibFFM/preds_test_ffm.txt', 'LibFFM/preds_test_ffm_2.txt', 'LibFFM/preds_test_ffm_3.txt']\n",
    "\n",
    "preds_test_ffm = np.concatenate([pd.read_csv(file, header=None).values for file in files], axis=1)\n",
    "print(preds_test_ffm.shape)\n",
    "print('Mean: ', np.mean(preds_test_ffm, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2327952, 3)\n",
      "Mean:  [0.00267422 0.00279109 0.00279529]\n"
     ]
    }
   ],
   "source": [
    "files = ['LibFFM/preds_valid_ffm.txt', 'LibFFM/preds_valid_ffm_2.txt', 'LibFFM/preds_valid_ffm_3.txt']\n",
    "\n",
    "preds_valid_ffm = np.concatenate([pd.read_csv(file, header=None).values for file in files], axis=1)\n",
    "print(preds_valid_ffm.shape)\n",
    "print('Mean: ', np.mean(preds_valid_ffm, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv('instance-1/home/klauke_peter/.kaggle/competitions/talkingdata-adtracking-fraud-detection/sample_submission.csv.zip')\n",
    "df_submission.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  rows are NaN in valid file\n",
      "4748  rows are NaN in test file\n",
      "0  rows are NaN in valid file\n",
      "0  rows are NaN in test file\n",
      "0  rows are NaN in valid file\n",
      "4748  rows are NaN in test file\n"
     ]
    }
   ],
   "source": [
    "for i in range(preds_valid_ffm.shape[1]):\n",
    "    srs_mask_valid = np.isnan(preds_valid_ffm[:, i])\n",
    "    print(np.sum(srs_mask_valid), ' rows are NaN in valid file')\n",
    "    preds_valid_ffm[srs_mask_valid, i] = np.mean(preds_valid_lgb[srs_mask_valid], axis=1)\n",
    "\n",
    "    srs_mask_test = np.isnan(preds_test_ffm[:, i])\n",
    "    print(np.sum(srs_mask_test), ' rows are NaN in test file')\n",
    "    preds_test_ffm[srs_mask_test, i] = np.mean(preds_test_lgb[srs_mask_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_valid\n",
      "Finished df_valid, shape: (5000000, 43)\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('instance-1/home/klauke_peter/store_enc_chunks.h5',  mode='r') as store:\n",
    "    \n",
    "    df_valid =  downcast_dtypes(store.select('df_valid'))\n",
    "    df_valid = to_drop(df_valid)\n",
    "    print('Loaded df_valid')\n",
    "    df_valid = downcast_dtypes(df_valid)\n",
    "    print('Finished df_valid, shape:', df_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid shape:  (2327952, 43)\n"
     ]
    }
   ],
   "source": [
    "df_valid = df_valid.loc[ ((df_valid.minute_of_day > 295) & (df_valid.minute_of_day < 365))\n",
    "                       | ((df_valid.minute_of_day > 535) & (df_valid.minute_of_day < 665))\n",
    "                       | ((df_valid.minute_of_day > 770) & (df_valid.minute_of_day < 905))]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('valid shape: ', df_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model score\n",
    "\n",
    "Score for the Field-Aware Factorization machine is lower than the score for the LightGBM model. This is probably caused by non-optimal hyperparameters. The Field-Aware Factorization Machine turned out to be quite unhandy for this amount of data. Nonetheless it contributes to the blend by some nice amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFM0 AUC (valid): 0.97656\n",
      "FFM1 AUC (valid): 0.97575\n",
      "FFM2 AUC (valid): 0.97575\n",
      "FFM AUC (valid): 0.97610\n",
      "\n",
      "LGB0 AUC (valid): 0.98352\n",
      "LGB1 AUC (valid): 0.98242\n",
      "LGB2 AUC (valid): 0.98259\n",
      "LGB AUC (valid): 0.98320\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(preds_valid_ffm.shape[1]):\n",
    "    print('FFM{} AUC (valid): {:0.5f}'.format(i, roc_auc_score(df_valid.is_attributed, preds_valid_ffm[:, i])))\n",
    "    \n",
    "preds_valid_ffm_mean = np.mean(preds_valid_ffm, axis=1)\n",
    "print('FFM AUC (valid): {:0.5f}'.format(roc_auc_score(df_valid.is_attributed, preds_valid_ffm_mean)))  \n",
    "print('')\n",
    "    \n",
    "for i in range(preds_valid_lgb.shape[1]):\n",
    "    print('LGB{} AUC (valid): {:0.5f}'.format(i, roc_auc_score(df_valid.is_attributed, preds_valid_lgb[:, i])))\n",
    "    \n",
    "preds_valid_lgb_mean = np.mean(preds_valid_lgb, axis=1)\n",
    "print('LGB AUC (valid): {:0.5f}'.format(roc_auc_score(df_valid.is_attributed, preds_valid_lgb_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized blending weights\n",
      "ffm 1: 0.71\n",
      "ffm 2: 1.00\n",
      "ffm 3: 1.30\n",
      "lgb 1: 0.50\n",
      "lgb 2: 0.00\n",
      "lgb 3: 0.01\n"
     ]
    }
   ],
   "source": [
    "from ensemble.blending_optimizer import BlendingOptimizer\n",
    "\n",
    "bo = BlendingOptimizer(roc_auc_score)\n",
    "\n",
    "weights = bo.fit(np.concatenate([preds_valid_ffm.T, preds_valid_lgb.T], axis=0),\n",
    "                 df_valid.loc[:, 'is_attributed'],\n",
    "                 step=0.01,\n",
    "                 init_weights=[0.7, 1, 1.3, 0.5, 0, 0])\n",
    "\n",
    "for model, weight in zip(['ffm 1', 'ffm 2', 'ffm 3', 'lgb 1', 'lgb 2', 'lgb 3'], weights):\n",
    "    print(model, weight)\n",
    "    \n",
    "print('Optimized blending weights')\n",
    "for w in  bo.weights:\n",
    "    print('{:0.2f}'.format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blended score:  0.9837291790368998\n"
     ]
    }
   ],
   "source": [
    "print('Blended score: ', bo.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.017205\n",
       "1         1       0.002623\n",
       "2         2       0.000304\n",
       "3         3       0.003242\n",
       "4         4       0.003437"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test = bo.predict(np.concatenate([preds_test_ffm.T, preds_test_lgb.T], axis=0))\n",
    "\n",
    "df_submission.loc[:, 'is_attributed'] = blend_test\n",
    "\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.016878\n",
       "1         1       0.002600\n",
       "2         2       0.000302\n",
       "3         3       0.003211\n",
       "4         4       0.003404"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.to_csv('submission.csv.gz', index = False, compression = 'gzip', float_format='%.8f')\n",
    "\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "subname = '3xffmada0.2 3xlgb, w=(0.71, 1.00, 1.30, 0.50, 0.00, 0.01)'\n",
    "os.system('kaggle competitions submit -c talkingdata-adtracking-fraud-detection -f submission.csv.gz -m \"{}\"'.format(subname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
